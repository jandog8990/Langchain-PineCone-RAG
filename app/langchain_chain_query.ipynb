{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone as PineconeClient\n",
    "from pinecone.grpc import PineconeGRPC\n",
    "from pinecone import ServerlessSpec\n",
    "from dotenv import dotenv_values\n",
    "# from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "#from langchain_community.embeddings import CohereEmbeddings\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "import requests\n",
    "import json\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "env_key = config[\"PINE_CONE_ENV_KEY\"]\n",
    "api_key = config[\"PINE_CONE_API_KEY\"]\n",
    "openai_api_key=config[\"OPENAI_API_KEY\"]\n",
    "cohere_api_key = config[\"COHERE_API_KEY\"]\n",
    "#pc_index = config[\"INDEX_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pineCone = PineconeClient(\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the cohere embeddings\n",
    "from pinecone.grpc import PineconeGRPC\n",
    "from pinecone import ServerlessSpec\n",
    "\n",
    "pc = PineconeGRPC()\n",
    "index_name = 'cohere-wikipedia'\n",
    "embeddings = CohereEmbeddings(model=\"multilingual-22-12\", cohere_api_key=cohere_api_key)\n",
    "vectorstore = Pinecone.from_existing_index(index_name=index_name, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch wiki using id\n",
    "def fetch_wiki_page(id):\n",
    "    # expand the context with which we search for chunks outside of LLM\n",
    "    url = f\"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&format=json&pageids={id}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    page_content = list(data['query']['pages'].values())[0]['extract']\n",
    "    return page_content\n",
    "\n",
    "# fetch the \n",
    "def fetch_url(x):\n",
    "    urls = [doc.metadata['url'] for doc in x['context']]\n",
    "    ids = [url.split('=')[-1] for url in urls]\n",
    "    contents = [fetch_wiki_page(id)[:32000] for id in ids]\n",
    "    return {\"context\": contents, \"question\": x[\"question\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain result output:\n",
      "Film noir is a cinematic term used primarily to describe stylized Hollywood crime dramas, particularly those that emphasize cynical attitudes and motivations. The classic period of American film noir is generally regarded as the 1940s and 1950s. This era of film noir is associated with a low-key, black-and-white visual style that has roots in German Expressionist cinematography. The stories and attitudes of classic noir often derive from the hardboiled school of crime fiction that emerged in the United States during the Great Depression.\n"
     ]
    }
   ],
   "source": [
    "# RAG Prompt\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.load.dump import dumps\n",
    "from langsmith import traceable\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# RAG Model\n",
    "#    | RunnableLambda(fetch_url)\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4-1106-preview\", openai_api_key=openai_api_key)\n",
    "\n",
    "# create an autotrace for the pipeline\n",
    "# TODO: Note we do not need traceable here as we've created a new LangSmith project\n",
    "# to log all of our LangChain projects\n",
    "# @traceable\n",
    "chain = (\n",
    "    RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()})\n",
    "    | RunnableLambda(fetch_url) # pipe the entire context from the url\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_result = chain.invoke(\"What is film noir?\")\n",
    "\n",
    "# Invoke a question to the chain\n",
    "#    SystemMessage(content=\"You're a great assistant\"),\n",
    "# message = HumanMessage(content=\"What is film noir?\")\n",
    "# chain_result = chain.invoke(\"what is film noir?\")\n",
    "# chain_result = chain.invoke(\"what is film noir?\")\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are Micheal Jordan.\"),\n",
    "    HumanMessage(content=\"Which shoe manufacturer are you associated with?\"),\n",
    "]\n",
    "# chain_result = chain.invoke(messages)\n",
    "#chain_result = chain.invoke(\"What is film noir?\")\n",
    "# chain_result = chain.run(\"What is film noir?\")\n",
    "# chain_result = pipeline(\"What is film noir?\")\n",
    "print(\"Chain result output:\")\n",
    "print(chain_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
